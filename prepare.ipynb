{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_data(input_path):\n",
    "    all_imgs = []\n",
    "\n",
    "    classes_count = {}\n",
    "\n",
    "    class_mapping = {}\n",
    "\n",
    "    img_class_mapping = {}\n",
    "\n",
    "    visualise = False\n",
    "\n",
    "    # not using vOC2007, 2012 only\n",
    "    # data_paths = [os.path.join(input_path, s) for s in ['VOC2007', 'VOC2012']]\n",
    "    data_paths = [os.path.join(input_path, s) for s in ['VOC2012']]\n",
    "\n",
    "    print('Parsing annotation files')\n",
    "\n",
    "    for data_path in data_paths:\n",
    "\n",
    "        annot_path = os.path.join(data_path, 'Annotations')\n",
    "        imgs_path = os.path.join(data_path, 'JPEGImages')\n",
    "        imgsets_path_trainval = os.path.join(data_path, 'ImageSets', 'Main', 'trainval.txt')\n",
    "        imgsets_path_test = os.path.join(data_path, 'ImageSets', 'Main', 'test.txt')\n",
    "\n",
    "        trainval_files = []\n",
    "        test_files = []\n",
    "        try:\n",
    "            with open(imgsets_path_trainval) as f:\n",
    "                for line in f:\n",
    "                    trainval_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        try:\n",
    "            with open(imgsets_path_test) as f:\n",
    "                for line in f:\n",
    "                    test_files.append(line.strip() + '.jpg')\n",
    "        except Exception as e:\n",
    "            if data_path[-7:] == 'VOC2012':\n",
    "                # this is expected, most pascal voc distibutions dont have the test.txt file\n",
    "                pass\n",
    "            else:\n",
    "                print(e)\n",
    "\n",
    "        annots = [os.path.join(annot_path, s) for s in os.listdir(annot_path)]\n",
    "        idx = 0\n",
    "        for annot in annots:\n",
    "            try:\n",
    "                idx += 1\n",
    "\n",
    "                et = ET.parse(annot)\n",
    "                element = et.getroot()\n",
    "\n",
    "                element_objs = element.findall('object')\n",
    "                element_filename = element.find('filename').text\n",
    "                element_width = int(element.find('size').find('width').text)\n",
    "                element_height = int(element.find('size').find('height').text)\n",
    "\n",
    "                if len(element_objs) > 0:\n",
    "                    annotation_data = {'filepath': os.path.join(imgs_path, element_filename), 'width': element_width,\n",
    "                                       'height': element_height, 'bboxes': []}\n",
    "\n",
    "                    if element_filename in trainval_files:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "                    elif element_filename in test_files:\n",
    "                        annotation_data['imageset'] = 'test'\n",
    "                    else:\n",
    "                        annotation_data['imageset'] = 'trainval'\n",
    "\n",
    "                for element_obj in element_objs:\n",
    "                    class_name = element_obj.find('name').text\n",
    "                    if class_name not in classes_count:\n",
    "                        classes_count[class_name] = 1\n",
    "                    else:\n",
    "                        classes_count[class_name] += 1\n",
    "\n",
    "                    if class_name not in class_mapping:\n",
    "                        class_mapping[class_name] = len(class_mapping)\n",
    "\n",
    "                    obj_bbox = element_obj.find('bndbox')\n",
    "                    x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
    "                    y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
    "                    x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
    "                    y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
    "                    difficulty = int(element_obj.find('difficult').text) == 1\n",
    "                    annotation_data['bboxes'].append(\n",
    "                        {'class': class_name, 'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'difficult': difficulty})\n",
    "                all_imgs.append(annotation_data)\n",
    "\n",
    "                img_class_mapping[element_filename] = class_name\n",
    "\n",
    "                if visualise:\n",
    "                    img = cv2.imread(annotation_data['filepath'])\n",
    "                    for bbox in annotation_data['bboxes']:\n",
    "                        cv2.rectangle(img, (bbox['x1'], bbox['y1']), (bbox[\n",
    "                                                                          'x2'], bbox['y2']), (0, 0, 255))\n",
    "                    cv2.imshow('img', img)\n",
    "                    cv2.waitKey(0)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "    return all_imgs, classes_count, class_mapping, img_class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsing annotation files\n"
     ]
    }
   ],
   "source": [
    "all_imgs, classes_count, class_mapping, img_class_mapping  = get_data(\"/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Downloads/VOCdevkit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/pytorch-CycleGAN-and-pix2pix/datasets/PASCAL/Seg_image/\"\n",
    "\n",
    "path_to_car = \"/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/pytorch-CycleGAN-and-pix2pix/datasets/PASCAL/car/\"\n",
    "\n",
    "path_to_label = \"/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/pytorch-CycleGAN-and-pix2pix/datasets/PASCAL/Label_image/\"\n",
    "\n",
    "path_to_A = \"/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/pytorch-CycleGAN-and-pix2pix/datasets/PASCAL/car/A/\"\n",
    "path_to_B = \"/Users/xuejiaxin/Dropbox/My Mac (Jiaxin的MacBook Pro)/Documents/GitHub/pytorch-CycleGAN-and-pix2pix/datasets/PASCAL/car/B/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path_to_data)\n",
    "file_names = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "cars = []\n",
    "for s in file_names:\n",
    "    if img_class_mapping[s] == \"car\":\n",
    "        cars.append(s)\n",
    "\n",
    "len(cars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2008_004552.jpg 2008_004552.jpg\n2011_000239.jpg 2011_000239.jpg\n2009_000825.jpg 2009_000825.jpg\n132 17 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cars, cars, test_size=0.2, random_state=6, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=6, shuffle=True)\n",
    "\n",
    "print(X_train[0], y_train[0])\n",
    "print(X_test[0], y_test[0])\n",
    "print(X_val[0], y_val[0])\n",
    "print(len(X_train), len(X_test), len(X_val))\n",
    "\n",
    "\n",
    "for train in X_train:\n",
    "    copy(path_to_data + train, path_to_A + \"train\")\n",
    "    copy(path_to_label + train, path_to_B + \"train\")\n",
    "\n",
    "for test in X_test:\n",
    "    copy(path_to_data + test, path_to_A + \"test\")\n",
    "    copy(path_to_label + test, path_to_B + \"test\")\n",
    "\n",
    "for val in X_val:\n",
    "    copy(path_to_data + val, path_to_A + \"val\")\n",
    "    copy(path_to_label + val, path_to_B + \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python datasets/combine_A_and_B.py --fold_A \"./datasets/PASCAL/car/A\" --fold_B \"./datasets/PASCAL/car/B\" --fold_AB \"./datasets/PASCAL/pairs_car\"\n",
    "\n",
    "python train.py --dataroot ./datasets/PASCAL/pairs_car --name PASCAL_pix2pix --model pix2pix --direction AtoB --gpu_ids -1 --display_id 0"
   ]
  }
 ]
}